{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbZ_n6EhciU1"
      },
      "source": [
        "Name: Godwin Mmaduagwu\n",
        "\n",
        "Student ID: 2235678\n",
        "\n",
        "Assessment: NLP Comparison\n",
        "\n",
        "Dataset Origin: https://huggingface.co/datasets/ogozcelik/english-fake-news-detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMCRDpficnVe"
      },
      "source": [
        "Generative AI (ChatGPT) was used for ideation and debugging only (planning code structure and resolving syntax issues). All analysis, implementation, and discussion are my own work."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Bqhq3EagKDD"
      },
      "source": [
        "# DATASET\n",
        "\n",
        "This project uses the ogozcelik/english-fake-news-detection dataset from HuggingFace, containing approximately 5,284 short text samples labelled as True, False, or Other. The dataset frames a three-class fake-news classification problem based on social media tweets.\n",
        "\n",
        "Detecting fake news in tweets requires understanding language to identify subtle cues that differentiate reliable information from fabricated or ambiguous statements. Thus, NLP is essential for a task like this.\n",
        "\n",
        "A key characteristic of this dataset is its class imbalance. The largest category, Other, contains around 2800 samples, while False has about 1700 and True only  about 700. This uneven distribution significantly affects classifier performance, influencing decision boundaries and requiring careful evaluation to ensure models do not default to majority-class predictions. Additionally, the informal, conversational nature of the text makes preprocessing and robust embeddings necessary for effective downstream modelling.\n",
        "\n",
        "The preprocessing workflow includes loading the dataset from HuggingFace, converting it into a pandas DataFrame, and conducting exploratory checks on class distribution. Columns were renamed for clarity, and string labels were mapped to numerical codes. Finally, a stratified train-test split (random_state=42) was applied to preserve label proportions across sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-F7Q1c07XJSi"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "import seaborn as sb\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ds = load_dataset(\"ogozcelik/english-fake-news-detection\")\n",
        "\n",
        "df = ds['train'].to_pandas()\n",
        "df['label'].value_counts()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JP3pHIJepx-"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbh0hD4vfYoN"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df['category'] = df['label'].map({\"True\":0, \"False\":1, \"Other\":2})\n",
        "\n",
        "train_df, test_df = train_test_split(\n",
        "    df,\n",
        "    test_size=0.2,\n",
        "    stratify=df['category'],\n",
        "    random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ycav5e1tgZSN"
      },
      "outputs": [],
      "source": [
        "train_df = train_df.rename(columns={\"label\": \"tag\"})\n",
        "test_df = test_df.rename(columns={\"label\": \"tag\"})\n",
        "\n",
        "train_df = train_df.rename(columns={\"category\": \"label\"})\n",
        "test_df = test_df.rename(columns={\"category\": \"label\"})\n",
        "\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wl9H605BigSh"
      },
      "source": [
        "# REPRESENTATION LEARNING\n",
        "\n",
        "The project implements two distinct strategies for transforming raw tweets into numerical representations suitable for machine learning.\n",
        "\n",
        "## Sentence-BERT (SBERT)\n",
        "The first pathway uses Sentence-BERT (all-MiniLM-L6-v2), a lightweight 6-layer MiniLM model that generates 384-dimensional sentence embeddings. These embeddings are precomputed and remain frozen throughout training. Because SBERT captures contextual semantics at the sentence level, it performs well on short, noisy text while remaining efficient with resources.\n",
        "\n",
        "After embedding, these fixed vectors are passed to classical machine-learning classifiers such as Logistic Regression and XGBoost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueJt6-DjhQe3"
      },
      "outputs": [],
      "source": [
        "# encoding using sentenceBERT\n",
        "\n",
        "X_train = train_df[\"tweet\"].tolist()\n",
        "X_test  = test_df[\"tweet\"].tolist()\n",
        "\n",
        "y_train = train_df[\"label\"].tolist()\n",
        "y_test  = test_df[\"label\"].tolist()\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "X_train_emb = model.encode(X_train, convert_to_numpy=True)\n",
        "X_test_emb  = model.encode(X_test, convert_to_numpy=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpF5FSaujxuV"
      },
      "source": [
        "## DistilBERT\n",
        "\n",
        "The second pathway relies on DistilBERT, which operates very differently. Instead of producing a static embedding, DistilBERT tokenizes each input and processes it through a transformer encoder that is fine-tuned during training.\n",
        "\n",
        "The model updates its internal hidden states and weights using the classification loss, allowing it to learn task-specific features and adapt its language understanding (from the pre-training on general text data) to this fake-news dataset. This dynamic representation typically captures deeper linguistic cues, especially when subtle differences distinguish True, False, and Other labels.\n",
        "\n",
        "Weighing these two pathways, SBERT provides fast, fixed semantic vectors, while DistilBERT offers an end-to-end trainable pipeline.\n",
        "\n",
        "Together, these approaches demonstrate two complementary embedding philosophies: precomputed semantic encoding (static embedding) versus adaptive transformer-based representation learning (dynamic)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OurMJeMJpC2g"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "train_ds = Dataset.from_pandas(train_df)\n",
        "test_ds = Dataset.from_pandas(test_df)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "def encode(batch):\n",
        "    return tokenizer(\n",
        "        batch['tweet'],\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=64\n",
        "    )\n",
        "\n",
        "train_ds = train_ds.map(encode, batched=True)\n",
        "test_ds = test_ds.map(encode, batched=True)\n",
        "\n",
        "train_ds = train_ds.with_format(\"torch\")\n",
        "test_ds = test_ds.with_format(\"torch\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsxAj-okoA6w"
      },
      "source": [
        "# ALGORITHMS\n",
        "\n",
        "This project evaluates three learning algorithms. Originally, the two pipelines for this task were SBERT+LR and DistilBERT. XGBoost was added as a constrasting classical model when LR delivered subpar results.\n",
        "\n",
        "## Pipeline 1 - SBERT + Logistic Regression\n",
        "\n",
        "Logistic Regression (LR) is used as the primary classifier for the fixed 384-dimensional SBERT embeddings. LR is a linear model that learns a set of weight vectors that best separate the three classes (True, False, Other) based on the semantic features encoded in the embeddings.\n",
        "\n",
        "Because SBERT already captures contextual meaning and compresses each tweet into a dense semantic space, a simple linear boundary might be sufficient for classification.\n",
        "\n",
        "There is risk bias toward the majority classes, so the model uses class_weight=\"balanced\", ensuring that minority classes contribute proportionally to the loss function.\n",
        "\n",
        "LR models linearly separable relationships in embedding space and provides a strong baseline for evaluating the impact of more complex algorithms. Its low computational cost also makes it ideal as the first pipeline for semantic-embedding-based classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOj1q9htFGPg"
      },
      "outputs": [],
      "source": [
        "# train logistic regression\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clf = LogisticRegression(max_iter=3000, class_weight=\"balanced\")\n",
        "clf.fit(X_train_emb, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eHKIFRXGEIv"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "pred = clf.predict(X_test_emb)\n",
        "\n",
        "print(\"Sentence-BERT + LR Results\\n\")\n",
        "print(classification_report(y_test, pred))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgjD07ACG2YH"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sb\n",
        "\n",
        "# visualize the mistakes\n",
        "cm = confusion_matrix(y_test, pred)\n",
        "sb.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.title(\"Logistic Regression Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DCydf9WqHF3"
      },
      "source": [
        "## Pipeline 1b - SBERT + XGBoost (multi-class softprob)\n",
        "\n",
        "The secondary classical ML model is XGBoost, configured with the multi:softprob objective for multi-class classification. XGBoost is an ensemble of gradient-boosted decision trees, designed to capture non-linear relationships between features.\n",
        "\n",
        "By training an ensemble of weak learners that loop to correct each other's errors, the model evaluates hundreds or thousands of decision boundaries in the SBERT embedding space.\n",
        "\n",
        "This makes XGBoost an interesting contrast to Logistic Regression. LR assumes linear separability, while XGBoost can model complex, non-linear interactions across the 384 embedding dimensions.\n",
        "\n",
        "This capability often yields better performance on imbalanced datasets, especially when certain classes depend on patterns that aren't linearly separable. XGBoost's regularization and shrinkage mechanisms also help control overfitting while exploiting the semantic richness of SBERT vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKS46TtNNU4T"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "params = {\n",
        "    \"objective\": \"multi:softprob\",\n",
        "    \"num_class\": 3,\n",
        "    \"eval_metric\": \"mlogloss\",\n",
        "    \"eta\": 0.1,\n",
        "    \"max_depth\": 6,\n",
        "    \"subsample\": 0.9,\n",
        "    \"colsample_bytree\": 0.9,\n",
        "    \"scale_pos_weight\": 1\n",
        "}\n",
        "\n",
        "dtrain = xgb.DMatrix(X_train_emb, label=y_train)\n",
        "dtest  = xgb.DMatrix(X_test_emb, label=y_test)\n",
        "\n",
        "model = xgb.train(\n",
        "    params=params,\n",
        "    dtrain=dtrain,\n",
        "    num_boost_round=200,\n",
        "    evals=[(dtest, \"test\")],\n",
        "    verbose_eval=20\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSIq31T_OGA4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "probs = model.predict(dtest)\n",
        "y_pred = np.argmax(probs, axis=1)\n",
        "\n",
        "print(\"Sentence-BERT + XGBoost Results\\n\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion matrix:\\n\", cm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QX693buHqy9M"
      },
      "source": [
        "## Pipeline 2 - DistilBERT Fine-Tuning\n",
        "\n",
        "The second main pipeline fine-tunes DistilBERT, a compressed version of BERT that retains most of BERT's performance while being faster and lighter. Unlike SBERT embeddings, DistilBERT does not rely on frozen representations. Instead, the transformer's internal weights are updated during training so that it learns features specific to this fake-news dataset.\n",
        "\n",
        "The HuggingFace Trainer manages batching, optimization, and evaluation, while looping back across all transformer layers. This allows the model to adapt its token-level and sentence-level representations based on the classification gradients.\n",
        "\n",
        "Fine-tuning often yields better performance than classical ML applied to fixed embeddings. The model updates its understanding of syntax, semantics, and subtle linguistic markers of misinformation.\n",
        "\n",
        "However, fine-tuning has higher computational cost and a greater risk of overfitting, especially with a dataset of just over 5k samples. However, transformer-based models still outperform classical models where nuance matters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bT3DnUoyVeQ"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\",\n",
        "    num_labels=3\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHbXODvD0YCw"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./fake_news_model\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    report_to=\"none\",\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RIjxnXLj0ruq"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=test_ds\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4ijsNJWJ5Sc"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "predictions = trainer.predict(test_ds)\n",
        "y_pred = predictions.predictions.argmax(-1)\n",
        "y_true = predictions.label_ids\n",
        "\n",
        "print(\"DistilBERT Classification Report:\")\n",
        "print(classification_report(y_true, y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WiKduFoTK7lz"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(\"Confusion matrix:\\n\", cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t06GNyj_sgnV"
      },
      "source": [
        "# EVALUATION\n",
        "\n",
        "Model performance was assessed using an 80/20 stratified train-test split to preserve the dataset's class proportions. The evaluation included accuracy, precision, recall, F1-score, and confusion matrices, which are essential for interpreting results in a three-class setup with significant imbalance.\n",
        "\n",
        "Because the dataset is skewed toward the Other class, accuracy alone would give an inflated view of performance; metrics like macro-averaged F1 offer a more reliable picture of how well each class is handled. Confusion matrices further reveal that the True class is consistently the hardest to classify, largely due to its low support, while Other is the easiest.\n",
        "\n",
        "The SBERT + Logistic Regression pipeline shows solid performance on the majority classes but struggles with the minority True class. As a linear classifier, LR finds it difficult to capture subtle semantic differences, and imbalance amplifies this limitation. The SBERT + XGBoost model offers a slight improvement, benefiting from its ability to model non-linear relationships in the embedding space and producing more balanced class-wise results.\n",
        "\n",
        "The DistilBERT fine-tuned model delivers the strongest overall performance. Its ability to learn task-specific language representations enables higher recall and F1 on the minority class.\n",
        "\n",
        "Overall, deeper contextual models outperform shallow classifiers on semantic tasks like fake-news detection."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}